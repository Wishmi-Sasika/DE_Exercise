{
  "cells": [
    {
      "cell_type": "code",
      "id": "T8rPdzFAiCKcuQ3nOTNPa5Kb",
      "metadata": {
        "tags": [],
        "id": "T8rPdzFAiCKcuQ3nOTNPa5Kb",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1760205281890,
          "user_tz": -330,
          "elapsed": 2573,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "source": [
        "import os\n",
        "import json\n",
        "import random\n",
        "import requests\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta, timezone\n",
        "from typing import Dict, Any\n",
        "\n",
        "from google.cloud import bigquery\n",
        "from google.cloud.bigquery import LoadJobConfig, SourceFormat, WriteDisposition\n",
        "from google.api_core.exceptions import NotFound"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PROJECT_ID = \"analytics-pipeline-assessment\"\n",
        "DATASET_ID = \"analytics_dw\"\n",
        "\n",
        "bq = bigquery.Client(project = PROJECT_ID)"
      ],
      "metadata": {
        "id": "ldLFCFxfyHBZ",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1760205281891,
          "user_tz": -330,
          "elapsed": 5,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "ldLFCFxfyHBZ",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logging function"
      ],
      "metadata": {
        "id": "jaTBKBb_RH1H"
      },
      "id": "jaTBKBb_RH1H"
    },
    {
      "cell_type": "code",
      "source": [
        "def log(step: str, **kwargs):\n",
        "\n",
        "  ist = timezone(timedelta(hours=5, minutes=30))\n",
        "  ist_time = datetime.now(ist).isoformat()\n",
        "\n",
        "  print(json.dumps({\"ts\": ist_time, \"Step\": step, **kwargs}))"
      ],
      "metadata": {
        "id": "d_CYn6FhyfO4",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1760205281891,
          "user_tz": -330,
          "elapsed": 5,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "d_CYn6FhyfO4",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Attendance data generator"
      ],
      "metadata": {
        "id": "qJCat2rsRgF5"
      },
      "id": "qJCat2rsRgF5"
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_attendance():\n",
        "\n",
        "  # Parameters\n",
        "  num_records = 3_000_000\n",
        "  output_file = \"attendance_dataset_3m.csv\"\n",
        "\n",
        "  # Sample data\n",
        "  regions = [\"North America\", \"Europe\", \"Asia\", \"South America\", \"Africa\", \"Oceania\"]\n",
        "  countries = {\n",
        "      \"North America\": [\"USA\", \"Canada\", \"Mexico\"],\n",
        "      \"Europe\": [\"Germany\", \"France\", \"UK\", \"Italy\"],\n",
        "      \"Asia\": [\"China\", \"India\", \"Japan\", \"Singapore\"],\n",
        "      \"South America\": [\"Brazil\", \"Argentina\", \"Chile\"],\n",
        "      \"Africa\": [\"South Africa\", \"Nigeria\", \"Egypt\"],\n",
        "      \"Oceania\": [\"Australia\", \"New Zealand\"]\n",
        "  }\n",
        "  departments = [\"IT\", \"Sales\", \"Marketing\", \"HR\", \"Finance\", \"Operations\"]\n",
        "  first_names = [\"Alice\", \"Bob\", \"Chen\", \"Daniela\", \"Ethan\", \"Fatima\", \"George\", \"Hiro\", \"Isabella\", \"Juan\"]\n",
        "  last_names = [\"Johnson\", \"Smith\", \"Wei\", \"Lopez\", \"Brown\", \"Hassan\", \"Wilson\", \"Tanaka\", \"Rossi\", \"Martinez\"]\n",
        "  statuses = [\"Present\", \"Absent\", \"Remote\"]\n",
        "\n",
        "  # Generator function\n",
        "  def generate_attendance_data(n):\n",
        "      for i in range(1, n+1):\n",
        "          staff_id = f\"ST{i:07d}\"\n",
        "          name = f\"{random.choice(first_names)} {random.choice(last_names)}\"\n",
        "          region = random.choice(regions)\n",
        "          country = random.choice(countries[region])\n",
        "          department = random.choice(departments)\n",
        "          date = datetime(2020, 1, 1) + timedelta(days=random.randint(0, 1825))  # 5 years\n",
        "          status = random.choices(statuses, weights=[0.7, 0.1, 0.2])[0]  # more likely to be Present\n",
        "          if status == \"Present\" or status == \"Remote\":\n",
        "              check_in_hour = random.randint(8, 10)\n",
        "              check_in_minute = random.randint(0, 59)\n",
        "              check_out_hour = random.randint(16, 18)\n",
        "              check_out_minute = random.randint(0, 59)\n",
        "              check_in = f\"{check_in_hour:02d}:{check_in_minute:02d}\"\n",
        "              check_out = f\"{check_out_hour:02d}:{check_out_minute:02d}\"\n",
        "          else:\n",
        "              check_in = \"-\"\n",
        "              check_out = \"-\"\n",
        "\n",
        "          yield [\n",
        "              staff_id, name, region, country, department, date.strftime(\"%Y-%m-%d\"),\n",
        "              status, check_in, check_out\n",
        "          ]\n",
        "\n",
        "  # Write CSV in chunks\n",
        "  columns = [\"StaffID\", \"Name\", \"Region\", \"Country\", \"Department\", \"Date\", \"Status\", \"CheckInTime\", \"CheckOutTime\"]\n",
        "  chunk_size = 100_000\n",
        "\n",
        "  with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
        "      f.write(\",\".join(columns) + \"\\n\")\n",
        "      for start in range(0, num_records, chunk_size):\n",
        "          chunk = list(generate_attendance_data(min(chunk_size, num_records - start)))\n",
        "          df = pd.DataFrame(chunk, columns=columns)\n",
        "          df.to_csv(f, header=False, index=False)\n",
        "\n",
        "  print(f\"âœ… Attendance dataset generated: {output_file}\")\n",
        "  log(\"gen.attendance.done\", file = output_file)"
      ],
      "metadata": {
        "id": "LvXMyNH-wIpF",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1760205281891,
          "user_tz": -330,
          "elapsed": 5,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "LvXMyNH-wIpF",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sales data generator"
      ],
      "metadata": {
        "id": "uAjOp05ARnK4"
      },
      "id": "uAjOp05ARnK4"
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_sales():\n",
        "\n",
        "  # Parameters\n",
        "  num_records = 3_000_000\n",
        "  output_file = \"sales_dataset_3m.csv\"\n",
        "\n",
        "  # Sample lists\n",
        "  regions = [\"North America\", \"Europe\", \"Asia\", \"South America\", \"Africa\", \"Oceania\"]\n",
        "  countries = {\n",
        "      \"North America\": [\"USA\", \"Canada\", \"Mexico\"],\n",
        "      \"Europe\": [\"Germany\", \"France\", \"UK\", \"Italy\"],\n",
        "      \"Asia\": [\"China\", \"India\", \"Japan\", \"Singapore\"],\n",
        "      \"South America\": [\"Brazil\", \"Argentina\", \"Chile\"],\n",
        "      \"Africa\": [\"South Africa\", \"Nigeria\", \"Egypt\"],\n",
        "      \"Oceania\": [\"Australia\", \"New Zealand\"]\n",
        "  }\n",
        "  currencies = {\n",
        "      \"USA\": \"USD\", \"Canada\": \"CAD\", \"Mexico\": \"MXN\",\n",
        "      \"Germany\": \"EUR\", \"France\": \"EUR\", \"UK\": \"GBP\", \"Italy\": \"EUR\",\n",
        "      \"China\": \"CNY\", \"India\": \"INR\", \"Japan\": \"JPY\", \"Singapore\": \"SGD\",\n",
        "      \"Brazil\": \"BRL\", \"Argentina\": \"ARS\", \"Chile\": \"CLP\",\n",
        "      \"South Africa\": \"ZAR\", \"Nigeria\": \"NGN\", \"Egypt\": \"EGP\",\n",
        "      \"Australia\": \"AUD\", \"New Zealand\": \"NZD\"\n",
        "  }\n",
        "  products = [\"Software\", \"Hardware\", \"Consulting\", \"Cloud Services\", \"Licenses\"]\n",
        "\n",
        "  # Generator function to avoid memory issues\n",
        "  def generate_sales_data(n):\n",
        "      for i in range(1, n+1):\n",
        "          region = random.choice(regions)\n",
        "          country = random.choice(countries[region])\n",
        "          product = random.choice(products)\n",
        "          currency = currencies[country]\n",
        "          date = datetime(2020, 1, 1) + timedelta(days=random.randint(0, 1825))  # 5 years\n",
        "          quantity = random.randint(1, 50)\n",
        "          unit_price = round(random.uniform(100, 5000), 2)\n",
        "          total_sales = round(quantity * unit_price, 2)\n",
        "\n",
        "          yield [\n",
        "              f\"S{i:07d}\", region, country, product, date.strftime(\"%Y-%m-%d\"),\n",
        "              currency, quantity, unit_price, total_sales\n",
        "          ]\n",
        "\n",
        "  # Write CSV in chunks\n",
        "  columns = [\"SaleID\", \"Region\", \"Country\", \"Product\", \"Date\", \"Currency\", \"Quantity\", \"UnitPrice\", \"TotalSales\"]\n",
        "  chunk_size = 100_000\n",
        "\n",
        "  with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
        "      f.write(\",\".join(columns) + \"\\n\")\n",
        "      for start in range(0, num_records, chunk_size):\n",
        "          chunk = list(generate_sales_data(min(chunk_size, num_records - start)))\n",
        "          df = pd.DataFrame(chunk, columns=columns)\n",
        "          df.to_csv(f, header=False, index=False)\n",
        "\n",
        "  print(f\"âœ… Sales dataset generated: {output_file}\")\n",
        "  log(\"gen.sales.done\", file = output_file)"
      ],
      "metadata": {
        "id": "5mz7WekQtLBQ",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1760205281891,
          "user_tz": -330,
          "elapsed": 4,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "5mz7WekQtLBQ",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finance data generator"
      ],
      "metadata": {
        "id": "G-l-S2nJbzAH"
      },
      "id": "G-l-S2nJbzAH"
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_finance():\n",
        "\n",
        "  # Parameters\n",
        "  num_records = 3_000_000\n",
        "  output_file = \"financial_dataset_3m.csv\"\n",
        "\n",
        "  regions = [\"North America\", \"Europe\", \"Asia\", \"South America\", \"Africa\", \"Oceania\"]\n",
        "  countries = {\n",
        "      \"North America\": [\"USA\", \"Canada\", \"Mexico\"],\n",
        "      \"Europe\": [\"Germany\", \"France\", \"UK\", \"Italy\"],\n",
        "      \"Asia\": [\"China\", \"India\", \"Japan\", \"Singapore\"],\n",
        "      \"South America\": [\"Brazil\", \"Argentina\", \"Chile\"],\n",
        "      \"Africa\": [\"South Africa\", \"Nigeria\", \"Egypt\"],\n",
        "      \"Oceania\": [\"Australia\", \"New Zealand\"]\n",
        "  }\n",
        "  currencies = {\n",
        "      \"USA\": \"USD\", \"Canada\": \"CAD\", \"Mexico\": \"MXN\",\n",
        "      \"Germany\": \"EUR\", \"France\": \"EUR\", \"UK\": \"GBP\", \"Italy\": \"EUR\",\n",
        "      \"China\": \"CNY\", \"India\": \"INR\", \"Japan\": \"JPY\", \"Singapore\": \"SGD\",\n",
        "      \"Brazil\": \"BRL\", \"Argentina\": \"ARS\", \"Chile\": \"CLP\",\n",
        "      \"South Africa\": \"ZAR\", \"Nigeria\": \"NGN\", \"Egypt\": \"EGP\",\n",
        "      \"Australia\": \"AUD\", \"New Zealand\": \"NZD\"\n",
        "  }\n",
        "  products = [\"Software\", \"Hardware\", \"Consulting\", \"Cloud Services\", \"Licenses\"]\n",
        "\n",
        "  def generate_data(n):\n",
        "      for i in range(1, n+1):\n",
        "          region = random.choice(regions)\n",
        "          country = random.choice(countries[region])\n",
        "          currency = currencies[country]\n",
        "          product = random.choice(products)\n",
        "          date = datetime(2020, 1, 1) + timedelta(days=random.randint(0, 1825))\n",
        "          revenue = round(random.uniform(1000, 100000), 2)\n",
        "          expense = round(revenue * random.uniform(0.4, 0.9), 2)\n",
        "          profit = revenue - expense\n",
        "\n",
        "          yield [\n",
        "              f\"T{i:07d}\", region, country, product, date.strftime(\"%Y-%m-%d\"),\n",
        "              currency, revenue, expense, profit\n",
        "          ]\n",
        "\n",
        "  columns = [\"TransactionID\", \"Region\", \"Country\", \"Product\", \"Date\", \"Currency\", \"Revenue\", \"Expense\", \"Profit\"]\n",
        "\n",
        "  chunk_size = 100_000\n",
        "  with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
        "      f.write(\",\".join(columns) + \"\\n\")\n",
        "      for start in range(0, num_records, chunk_size):\n",
        "          chunk = list(generate_data(min(chunk_size, num_records - start)))\n",
        "          df = pd.DataFrame(chunk, columns=columns)\n",
        "          df.to_csv(f, header=False, index=False)\n",
        "\n",
        "  print(f\"âœ… Finance dataset generated: {output_file}: {output_file}\")\n",
        "  log(\"gen.finance.done\", file = output_file)"
      ],
      "metadata": {
        "id": "huqnODO6vyy9",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1760205281891,
          "user_tz": -330,
          "elapsed": 4,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "huqnODO6vyy9",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_gen():\n",
        "\n",
        "  gen_attendance(), gen_sales(), gen_finance()\n",
        "\n",
        "data_gen()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nt7CEAXkReZs",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1760205428558,
          "user_tz": -330,
          "elapsed": 146671,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "d21201e6-1965-41f8-e55f-59fbcd43b90e"
      },
      "id": "Nt7CEAXkReZs",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Attendance dataset generated: attendance_dataset_3m.csv\n",
            "{\"ts\": \"2025-10-11T23:25:32.840996+05:30\", \"Step\": \"gen.attendance.done\", \"file\": \"attendance_dataset_3m.csv\"}\n",
            "âœ… Sales dataset generated: sales_dataset_3m.csv\n",
            "{\"ts\": \"2025-10-11T23:26:17.594463+05:30\", \"Step\": \"gen.sales.done\", \"file\": \"sales_dataset_3m.csv\"}\n",
            "âœ… Finance dataset generated: financial_dataset_3m.csv: financial_dataset_3m.csv\n",
            "{\"ts\": \"2025-10-11T23:27:04.719752+05:30\", \"Step\": \"gen.finance.done\", \"file\": \"financial_dataset_3m.csv\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ensuring dataset existance"
      ],
      "metadata": {
        "id": "jm-OzeTdSyIZ"
      },
      "id": "jm-OzeTdSyIZ"
    },
    {
      "cell_type": "code",
      "source": [
        "def ensure_dataset():\n",
        "\n",
        "  ds = f\"{PROJECT_ID}.{DATASET_ID}\"\n",
        "\n",
        "  try:\n",
        "    bq.get_dataset(ds)\n",
        "    log(\"dataset.exists\", dataset = ds)\n",
        "  except Exception:\n",
        "    bq.create_dataset(bigquery.Dataset(ds), exists_ok = True)\n",
        "    log(\"dataset.created\", dataset = ds)"
      ],
      "metadata": {
        "id": "nMgl5IuDReUf",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1760205428559,
          "user_tz": -330,
          "elapsed": 5,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "nMgl5IuDReUf",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SQL query executor"
      ],
      "metadata": {
        "id": "pfZ-I9VoSq9S"
      },
      "id": "pfZ-I9VoSq9S"
    },
    {
      "cell_type": "code",
      "source": [
        "def run_sql(sql: str):\n",
        "\n",
        "    return bq.query(sql).result()"
      ],
      "metadata": {
        "id": "HCB9vXn7ReW_",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1760205428559,
          "user_tz": -330,
          "elapsed": 4,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "HCB9vXn7ReW_",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DDL_SQL = f\"\"\"\n",
        "CREATE SCHEMA IF NOT EXISTS `{PROJECT_ID}.{DATASET_ID}`;\n",
        "\n",
        "CREATE TABLE IF NOT EXISTS `{PROJECT_ID}.{DATASET_ID}.dim_date` (\n",
        "  date_key DATE,\n",
        "  year INT64,\n",
        "  quarter INT64,\n",
        "  month INT64,\n",
        "  month_name STRING,\n",
        "  day_of_month INT64,\n",
        "  day_of_week INT64,\n",
        "  day_name STRING\n",
        ");\n",
        "\n",
        "CREATE TABLE IF NOT EXISTS `{PROJECT_ID}.{DATASET_ID}.dim_location` (\n",
        "  location_key STRING,\n",
        "  region STRING,\n",
        "  country STRING\n",
        ");\n",
        "\n",
        "CREATE TABLE IF NOT EXISTS `{PROJECT_ID}.{DATASET_ID}.dim_product` (\n",
        "  product_key STRING,\n",
        "  product_name STRING\n",
        ");\n",
        "\n",
        "CREATE TABLE IF NOT EXISTS `{PROJECT_ID}.{DATASET_ID}.dim_employee` (\n",
        "  employee_key STRING,\n",
        "  staffid STRING,\n",
        "  name STRING,\n",
        "  department STRING,\n",
        "  home_country STRING,\n",
        "  home_region STRING\n",
        ");\n",
        "\n",
        "CREATE TABLE IF NOT EXISTS `{PROJECT_ID}.{DATASET_ID}.dim_currency` (\n",
        "  currency_key STRING,\n",
        "  currency_code STRING,\n",
        "  date_to_usd NUMERIC\n",
        ");\n",
        "\n",
        "CREATE TABLE IF NOT EXISTS `{PROJECT_ID}.{DATASET_ID}.stg_attendance` (\n",
        "  StaffID STRING,\n",
        "  Name STRING,\n",
        "  Region STRING,\n",
        "  Country STRING,\n",
        "  Department STRING,\n",
        "  Date DATE,\n",
        "  Status STRING,\n",
        "  CheckInTime STRING,\n",
        "  CheckOutTime STRING\n",
        ");\n",
        "\n",
        "CREATE TABLE IF NOT EXISTS `{PROJECT_ID}.{DATASET_ID}.stg_sales` (\n",
        "  SaleID STRING,\n",
        "  Region STRING,\n",
        "  Country STRING,\n",
        "  Product STRING,\n",
        "  Date DATE,\n",
        "  Currency STRING,\n",
        "  Quantity INT64,\n",
        "  UnitPrice NUMERIC,\n",
        "  TotalSales NUMERIC\n",
        ");\n",
        "\n",
        "CREATE TABLE IF NOT EXISTS `{PROJECT_ID}.{DATASET_ID}.stg_finance` (\n",
        "  TransactionID STRING,\n",
        "  Region STRING,\n",
        "  Country STRING,\n",
        "  Product STRING,\n",
        "  Date DATE,\n",
        "  Currency STRING,\n",
        "  Revenue NUMERIC,\n",
        "  Expense NUMERIC,\n",
        "  Profit NUMERIC\n",
        ");\n",
        "\n",
        "CREATE TABLE IF NOT EXISTS `{PROJECT_ID}.{DATASET_ID}.fact_attendance` (\n",
        "  attendance_key STRING,\n",
        "  employee_key STRING,\n",
        "  location_key STRING,\n",
        "  date_key DATE,\n",
        "  status STRING,\n",
        "  checkin_time TIMESTAMP,\n",
        "  checkout_time TIMESTAMP\n",
        ");\n",
        "\n",
        "CREATE TABLE IF NOT EXISTS `{PROJECT_ID}.{DATASET_ID}.fact_sales` (\n",
        "  saleid STRING,\n",
        "  product_key STRING,\n",
        "  location_key STRING,\n",
        "  date_key DATE,\n",
        "  currency_key STRING,\n",
        "  quantity INT64,\n",
        "  conversion_rate_to_usd NUMERIC,\n",
        "  unit_price_usd NUMERIC,\n",
        "  total_sales_usd NUMERIC\n",
        ");\n",
        "\n",
        "CREATE TABLE IF NOT EXISTS `{PROJECT_ID}.{DATASET_ID}.fact_finance` (\n",
        "  transaction_id STRING,\n",
        "  product_key STRING,\n",
        "  location_key STRING,\n",
        "  date_key DATE,\n",
        "  currency_key STRING,\n",
        "  conversion_rate_to_usd NUMERIC,\n",
        "  revenue_usd NUMERIC,\n",
        "  expense_usd NUMERIC,\n",
        "  profit_usd NUMERIC\n",
        ");\n",
        "\"\"\"\n",
        "\n",
        "run_sql(DDL_SQL)\n",
        "log(\"ddl.applied\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nshp6ar-S1eg",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1760205433742,
          "user_tz": -330,
          "elapsed": 5187,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "f4c6dbd5-b507-4512-d72c-ac81f967ab9a"
      },
      "id": "nshp6ar-S1eg",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"ts\": \"2025-10-11T23:27:09.965021+05:30\", \"Step\": \"ddl.applied\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upload finance data to BQ"
      ],
      "metadata": {
        "id": "DhlVSJK5bNX9"
      },
      "id": "DhlVSJK5bNX9"
    },
    {
      "cell_type": "code",
      "source": [
        "def upload_finance_to_bq():\n",
        "    table_id = f\"{PROJECT_ID}.{DATASET_ID}.stg_finance\"\n",
        "    file_path = \"financial_dataset_3m.csv\"\n",
        "\n",
        "    # Read the CSV\n",
        "    df = pd.read_csv(file_path)\n",
        "\n",
        "    # Remove duplicates\n",
        "    before = len(df)\n",
        "    df = df.drop_duplicates(keep=\"first\")\n",
        "    after = len(df)\n",
        "    removed = before - after\n",
        "\n",
        "    # Upload cleaned data to BigQuery\n",
        "    job_config = bigquery.LoadJobConfig(\n",
        "        write_disposition=bigquery.WriteDisposition.WRITE_TRUNCATE\n",
        "    )\n",
        "    bq.load_table_from_dataframe(df, table_id, job_config=job_config).result()\n",
        "\n",
        "    # Log and print results\n",
        "    log(\"upload.finance.done\", table=table_id, rows_uploaded=after, duplicates_removed=removed)\n",
        "    print(f\"âœ… Uploaded {after:,} rows to {table_id}\")\n",
        "    print(f\"ðŸ§¹ Removed {removed:,} duplicate rows before upload.\")\n",
        "\n",
        "upload_finance_to_bq()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPkN3D5IS1b3",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1760205462480,
          "user_tz": -330,
          "elapsed": 28740,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "40dbbe60-3c66-4432-aee2-21eda7941b2f"
      },
      "id": "nPkN3D5IS1b3",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"ts\": \"2025-10-11T23:27:39.648633+05:30\", \"Step\": \"upload.finance.done\", \"table\": \"analytics-pipeline-assessment.analytics_dw.stg_finance\", \"rows_uploaded\": 3000000, \"duplicates_removed\": 0}\n",
            "âœ… Uploaded 3,000,000 rows to analytics-pipeline-assessment.analytics_dw.stg_finance\n",
            "ðŸ§¹ Removed 0 duplicate rows before upload.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qPQce_1yS1Yy",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1760205462481,
          "user_tz": -330,
          "elapsed": 4,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "qPQce_1yS1Yy",
      "execution_count": 11,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "name": "Test Notebook"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}